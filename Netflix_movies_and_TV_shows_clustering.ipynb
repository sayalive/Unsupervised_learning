{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "QHF8YVU7Yuh3",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayalive/Unsupervised_learning/blob/main/Netflix_movies_and_TV_shows_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n",
        "Netflix Movies and Tv Shows Clustering\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**  Sayali Shirishrao Deshmukh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The entertainment industry is highly competitive, and success depends on various factors such as genre, rating, production budget, cast, and more. A study was conducted to analyze the factors that impact the popularity of movies and TV shows on Netflix. The study utilized a dataset with approximately 12 variables to cluster movies and TV shows based on their popularity and audience preferences.\n",
        "\n",
        "To begin the analysis, data wrangling was performed, which involved handling missing values and checking unique values. The study found that there were 2389 missing values for the 'director' column, 718 for the 'cast' column, 507 for the 'country' column, and 10 for the 'date_added' column. These missing values were eliminated by dropping the corresponding rows.\n",
        "\n",
        "Next, exploratory data analysis (EDA) was conducted. The number of movies on Netflix exceeds the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform. The most common rating for TV shows is TV-MA, indicating a significant proportion of adult-oriented TV shows on Netflix. Moreover, TV-MA is also the most common rating for both movies and TV shows, suggesting that Netflix's content predominantly caters to an adult demographic, focusing on mature and potentially controversial themes.\n",
        "\n",
        "The years 2017 and 2018 witnessed the highest number of movie releases, while 2020 had the highest number of TV show releases. The growth rate of movie releases on Netflix is significantly higher than that of TV shows. Since 2015, there has been a substantial increase in the number of movies and TV show episodes available on Netflix. However, there has been a noticeable decline in the production of movies and TV show episodes after 2020, indicating that Netflix has prioritized expanding its movie content over TV shows.\n",
        "\n",
        "Based on the countplot, it can be observed that Netflix adds the highest number of movies and TV shows between October and January. This period seems to be the busiest time of the year for Netflix in terms of introducing new content to its platform. The United States has the highest number of content offerings on Netflix, followed by India, which boasts the highest number of movies.\n",
        "\n",
        "To cluster the shows, the study focused on six key attributes: director, cast, country, genre, rating, and description. These attributes were transformed into a 10,000-feature TFIDF vectorization, and Principal Component Analysis (PCA) was utilized to reduce the components to 3000, capturing more than 80% of the variance.\n",
        "\n",
        "Two clustering algorithms, namely K-Means and Agglomerative clustering, were employed to group the shows. K-Means identified 5 as the optimal number of clusters, while Agglomerative clustering suggested 7 clusters. These clusters were visualized using a dendrogram.\n",
        "\n",
        "Finally, a content-based recommender system was developed using the similarity matrix obtained through cosine similarity. This system offers personalized recommendations based on the user's watched shows, providing them with 10 top-notch suggestions to explore.\n",
        "\n",
        "In conclusion, the study highlighted significant trends in the Netflix dataset, including the contrasting growth rates of movies and TV shows, the busiest period for adding new content, and the content demographics. Through clustering and a content-based recommender system, personalized recommendations based on the user's viewing history were generated. This study provides valuable insights into the factors influencing the popularity of movies and TV shows on Netflix, establishing a basis for further research and analysis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings\n",
        "\n",
        "In this project, you are required to do\n",
        "\n",
        "1.Exploratory Data Analysis.\n",
        "\n",
        "2.Understanding what type content is available in different countries.\n",
        "\n",
        "3.Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "4.Clustering similar content by matching text-based features."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import missingno as msno\n",
        "%matplotlib inline\n",
        "\n",
        "# Word Cloud library\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# library used for textual data prerocessing\n",
        "import string\n",
        "string.punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# library used for Clusters impelementation\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# library used for building recommandation system\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Warnings library. Would help to throw away warnings caused.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading\n",
        "To load dataset first we have to mount the drive."
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mounting Drive"
      ],
      "metadata": {
        "id": "ahjubyTitJCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ffz2djc1tHZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Almabetter/Unsupervised_learning/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# count the number of duplicate rows in the DataFrame\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "duplicate_count = len(duplicate_rows)\n",
        "\n",
        "# print the result\n",
        "print(\"Number of duplicate rows: \", duplicate_count)\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Total null values\n",
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "id": "9Rzz_ISDNxlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 3631 null values in the dataset, 2389 null values in director column, 718 null values in cast column ,507 null values in country column ,10 in date_added and 7 in rating. so we need to handle the null values"
      ],
      "metadata": {
        "id": "kddZF4EjN6R0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset contains 7787 rows and 12 columns.Their are four columns containing missing values.The Total 3631 missing values present in the table"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following data shows Variable Description of each column.\n",
        "\n",
        "**Show_id**: Unique id for every movie/ Tv show\n",
        "\n",
        "**type**: Identifier-A movie or Tv show\n",
        "\n",
        "**director** :Director of the show\n",
        "\n",
        "**cast** :Actors involved.\n",
        "\n",
        "**Country** :Country of production\n",
        "\n",
        "**date_added**: Date it was added on netflix\n",
        "\n",
        "**release_year**: Actual release year of the show\n",
        "\n",
        "**rating** :TV rating of the show\n",
        "\n",
        "**duration**:Total duration in minutes or number of seasons.\n",
        "\n",
        "**listed_in**:Genre.\n",
        "\n",
        "**Description**: The summary description."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df['show_id'].unique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['type'].unique()"
      ],
      "metadata": {
        "id": "8tBU_k4y7lkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'].unique()"
      ],
      "metadata": {
        "id": "gDAqRatr73iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['director'].unique()"
      ],
      "metadata": {
        "id": "lMXsKzjWJYYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cast'].unique()"
      ],
      "metadata": {
        "id": "S4yiP6eNJf6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['country'].unique()"
      ],
      "metadata": {
        "id": "Z2-HIKOFJmxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_added'].unique()"
      ],
      "metadata": {
        "id": "ski-F9X5JwOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['release_year'].unique()"
      ],
      "metadata": {
        "id": "aMEhb_SaJ0uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating'].unique()"
      ],
      "metadata": {
        "id": "NZHVpVjQJ8J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['duration'].unique()"
      ],
      "metadata": {
        "id": "OBBuuKVWKAlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['listed_in'].unique()"
      ],
      "metadata": {
        "id": "p9lpmJgEKGZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'].unique()"
      ],
      "metadata": {
        "id": "51c9BJRFKPbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#Handling Null Values\n",
        "df['cast'].fillna(value='No cast',inplace=True)\n",
        "df['country'].fillna(value=df['country'].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "5i_5H-2M0MsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'date_added' and 'rating' contains an insignificant portion of the data so we will drop them from the dataset\n",
        "df.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "EXellUYj0PKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#again checking is there any null values are not\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "Y9GBMgkF0Rb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filled the null values in 'cast' column with 'No cast' Filled the null values in 'country' column with the mode of the column Dropped rows with null values in 'date_added' and 'rating' columns Dropped 'director' column Checked if there are any remaining null values in the dataset Some possible insights that can be derived from this dataset after the manipulations are done include:\n",
        "\n",
        "The most common country for Netflix content is likely the country that filled in the null values for the 'country' column The 'cast' column is important in the dataset, as there were null values that needed to be filled in order to keep the data complete The 'date_added' and 'rating' columns may not be important in the dataset, as they were dropped due to a small number of null values. However, this would depend on the specific analysis being done. The 'director' column was dropped, which may indicate that it is not a useful feature for the analysis.."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1\n",
        "Type"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='type', data=df, palette='pastel')\n",
        "#labeling of values\n",
        "plt.title('Number of Movies and TV Shows', fontsize=14)\n",
        "plt.xlabel('Type', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "#Visualization of number of movies and tv shows\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows us total count of movies and Tv shows present on Netflix.This is a countplot which displays frequency in each category in a clear way."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart gives us deep understanding of what we can see.Here we havw two options either we can see Tv shows or we can see movies.\n",
        "The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that there are more movies on Netflix than TV shows is unlikely to have a significant positive or negative business impact on its own. However, this information could be used in conjunction with other insights and data to inform business decisions.\n",
        "\n",
        "For example, if Netflix notices that TV shows are more popular with its subscribers than movies, it may decide to focus more on acquiring TV show content. Alternatively, if it sees that its original movie productions are gaining popularity, it may decide to invest more in that area.\n",
        "\n",
        "In terms of negative growth, the specific insight that there are more movies than TV shows on Netflix is unlikely to have a negative impact on its own. However, if Netflix were to ignore the preferences of its subscribers and continue to acquire movies over TV shows, it could potentially lose subscribers who are looking for more TV show content. Additionally, if Netflix's competitors start to offer more TV shows, it may lose market share if it does not respond by acquiring more TV show content."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2\n",
        "Rating"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "df['rating']"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning the Ratings into grouped categories\n",
        "ratings = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "df['target_ages'] = df['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "Z0wFS4knsjAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type should be a catego\n",
        "df['type'] = pd.Categorical(df['type'])\n",
        "\n",
        "# target_ages is another category (4 classes)\n",
        "df['target_ages'] = pd.Categorical(df['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])"
      ],
      "metadata": {
        "id": "hyLnM8zOsnt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "BVKyUPavsrUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating two extra columns\n",
        "tv_shows=df[df['type']=='TV Show']\n",
        "movies=df[df['type']=='Movie']\n"
      ],
      "metadata": {
        "id": "ymbo90hYsxhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group TV shows by 'rating' and count the number of shows in each rating category\n",
        "tv_ratings = tv_shows.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "\n",
        "# set figure dimensions\n",
        "fig_dims = (14,7)\n",
        "\n",
        "# create a figure and axis object with specified dimensions\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "# create a point plot using Seaborn's pointplot() function, with 'rating' on the x-axis and 'count' on the y-axis\n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "\n",
        "# set the plot title and font size\n",
        "plt.title('TV Show Ratings',size='20')\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EWJfb5U62ay2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Movie Ratings based on Target Age Groups\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('movie ratings')\n",
        "sns.countplot(x=movies['rating'],hue=movies['target_ages'],data=movies,order=movies['rating'].value_counts().index)"
      ],
      "metadata": {
        "id": "7Hkavpegs0cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a Bar chart which shows us the distribution of tv shows  ratings of all age type ie.Kids, Older kids, Teens and Adults."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the dataset, TV-MA is the most common rating for TV shows, with the highest number of occurrences in the 'rating' column. This indicates that a significant portion of the TV shows available on Netflix are intended for adult audiences.According to the dataset, TV-MA is the most common rating for both movies and TV shows. This indicates that a significant portion of the content available on Netflix is intended for adult audiences. Specifically, TV-MA has the highest number of occurrences in the 'rating' column for TV shows, while for movies it is also the most common rating. This suggests that Netflix's content caters to a primarily adult demographic, with a focus on mature and potentially controversial themes."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can have a positive impact on Netflix's business strategy. Knowing that TV-MA is the most common rating for both movies and TV shows, Netflix can continue to focus on producing and acquiring content that appeals to adult audiences. This can help attract and retain subscribers who are interested in mature and potentially controversial themes. Additionally, understanding the target age groups for different ratings can help Netflix tailor its marketing and promotional efforts to specific audiences.\n",
        "\n",
        "However, there is a potential negative impact as well. Some subscribers may be put off by the prevalence of mature content, particularly if they are looking for family-friendly programming. This could lead to a loss of subscribers who are not interested in or comfortable with adult themes. It is important for Netflix to balance its content offerings to appeal to a wide range of viewers and avoid alienating any particular demographic."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3\n",
        "Release Year"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#Creating a line chart to visualize the number of movies and TV shows released each year\n",
        "#Extracting the count of movies and TV shows for each year\n",
        "movies_year = movies['release_year'].value_counts().sort_index(ascending=False)\n",
        "tvshows_year = tv_shows['release_year'].value_counts().sort_index(ascending=False)\n",
        "\n",
        "#Creating a line plot using Seaborn\n",
        "sns.set(style='whitegrid', font_scale=1.2)\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "ax = sns.lineplot(x=movies_year.index, y=movies_year.values, color='maroon', label='Movies', linewidth=2.5, marker='o')\n",
        "ax = sns.lineplot(x=tvshows_year.index, y=tvshows_year.values, color='blue', label='TV Shows', linewidth=2.5, marker='o')\n",
        "\n",
        "#Customizing the plot\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_xlabel('Release Year', fontsize=14)\n",
        "ax.set_ylabel('Number of Titles', fontsize=14)\n",
        "ax.set_title('Production Growth Yearly', fontsize=18, pad=15)\n",
        "plt.legend(fontsize=14)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the last 20 years from the dataset\n",
        "last_20_years = range(2001, 2020)\n",
        "\n",
        "# Filter the dataset to only include movies from the last 20 years\n",
        "movies_last_20_years = movies[movies['release_year'].isin(last_20_years)]\n",
        "\n",
        "# Create a count plot of the number of movies released per year\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(x='release_year', data=movies_last_20_years, palette='mako', order=last_20_years)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Year of Release')\n",
        "plt.ylabel('Number of Movies Released')\n",
        "plt.title('Number of Movies Released per Year in the Last 20 Years')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UifBb3e420cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tvshows_year"
      ],
      "metadata": {
        "id": "n2x9u7Yk25SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter for movies released in the last 15 years\n",
        "movies_last_15_years = df[df['release_year'] >= 2008]\n",
        "\n",
        "# create a countplot with horizontal bars\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(y='release_year', data=movies_last_15_years, order=movies_last_15_years['release_year'].value_counts().index[:15])\n",
        "plt.title('Number of Movies Released per Year (2008-2022)', fontsize=16)\n",
        "plt.xlabel('Number of Movies')\n",
        "plt.ylabel('Release Year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gy4cDs9k2_Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "tPK_B6VM3CXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding columns of month and year of addition\n",
        "\n",
        "df['month'] = pd.DatetimeIndex(df['date_added']).month\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rhrF2qUz3HSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose this specific chart because it effectively conveys the message that the number of movies released on Netflix is growing faster than the number of TV shows. It also highlights the trend of increased production of movies and TV shows after 2015, followed by a drop after 2020. Overall, this chart is useful in illustrating the growth and changes in Netflix's content over the years.."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The years 2017 and 2018 had the highest number of movie releases, while 2020 had the highest number of TV show releases.\n",
        "\n",
        "The growth rate of movie releases on Netflix is significantly faster than that of TV shows.\n",
        "\n",
        "Since 2015, there has been a substantial increase in the number of movies and TV show episodes available on Netflix.\n",
        "\n",
        "However, there has been a notable drop in the number of movies and TV show episodes produced after 2020.\n",
        "\n",
        "It appears that Netflix has given more attention to increasing its movie content rather than TV shows, as the growth rate of movies has been much more significant than that of TV shows."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights may have a positive business impact for Netflix, as they show that increasing their movie content could be a successful strategy. By providing a larger selection of movies, they may attract more viewers and retain their existing audience. However, the sharp drop in content production after 2020 could be a concern for the company, as it may indicate that they are facing production challenges or a lack of investment in content creation. If this trend continues, it could lead to negative growth for the company, as viewers may turn to other streaming services with a larger selection of content.\n",
        "\n",
        "In conclusion, while the insights gained from the analysis suggest potential opportunities for Netflix, it is important to continue monitoring trends and adapting to changes in the market to ensure continued growth and success."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4\n",
        "\n",
        "Release_month"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Chart - 4 visualization code\n",
        "#visualization of month of movie release\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.countplot(x='month', data=df, palette='Set2')\n",
        "plt.title('Countplot of Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Countplot of Month by Type\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "sns.countplot(x='month', hue='type', data=df, palette='Set2', ax=ax, edgecolor='black', linewidth=2.5)\n",
        "ax.set_title('Countplot of Month by Type', fontsize=16)\n",
        "ax.set_xlabel('Month', fontsize=14)\n",
        "ax.set_ylabel('Count', fontsize=14)\n",
        "ax.legend(fontsize=12, title='Type', title_fontsize=12)\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "VHv1EDuO32TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a countplot which allows us to easily visualize and compare the number of movies and TV Shows added to the Netflix each month.Here we can clearly see that from October to January, there was a peak in the number of movies and TV shows added to Netflix. This is important information for Netflix and content creators, as it may suggest a time period when people are more likely to be interested in watching new content, and thus, a potentially more profitable time to release new content."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insight that the most content is added to Netflix from October to January can potentially help create a positive business impact. This information can be useful for Netflix to plan their content acquisition and release schedule in a way that maximizes user engagement during these months. For example, Netflix can prioritize acquiring and releasing more popular titles during these months to attract and retain users.\n",
        "\n",
        "However, it's important to note that the information from the countplot alone may not be sufficient to create a significant positive impact. Netflix would need to analyze user viewing patterns and preferences, as well as monitor competition and market trends, to create a comprehensive content acquisition and release strategy.\n",
        "\n",
        "Regarding negative growth, the countplot alone does not provide any insights that would lead to negative growth. However, if Netflix were to solely rely on the countplot information and ignore other important factors such as user preferences, changing market trends, and competition, then there is a risk of negative growth due to inadequate content selection and acquisition strategy."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5\n",
        "\n",
        "Genre"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 5 visualization code\n",
        "#Top 10 genres of movies\n",
        "top10_movies = movies['listed_in'].value_counts().index[0:10]\n",
        "#Visualization of code\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.countplot(y='listed_in', data=movies, order=top10_movies, palette='muted')\n",
        "plt.title('Top 10 Genres of Movies', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 10 Genres of Tv shows\n",
        "top10_tvshows = tv_shows['listed_in'].value_counts().index[0:10]\n",
        "#Visualization\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.countplot(y='listed_in', data=tv_shows, order=top10_tvshows, palette='pastel')\n",
        "plt.title('Top 10 Genres of TV Shows', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wTvIxdmq425I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose this chart because i ust wanted to know the total count of Tv shows and movies present on netflix."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Netflix's kids TV category is designed with parents in mind, offering a safe and secure viewing environment that allows them to have peace of mind while their kids enjoy their favorite shows. The parental controls feature allows parents to set age-appropriate content filters, monitor viewing history, and restrict access to certain shows or movies.\n",
        "\n",
        "So, whether you're looking for a way to keep your little ones entertained on a rainy day, or just want to bond with your family over a great TV show, Netflix's kids TV category is the perfect place to start. With its vast selection of entertaining and educational content, it's no wonder that kids TV remains one of the top genres on the platform."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top genre for TV shows on Netflix is kids TV, which includes a range of educational and entertaining content for children of all ages. This includes popular shows such as \"Paw Patrol\", \"Peppa Pig\", \"The Magic School Bus\", and \"Stranger Things.\"\n",
        "\n",
        "The insights gained from this information could definitely have a positive business impact. By knowing which genres are most popular, Netflix can tailor their content offerings and marketing strategies to appeal to their target audience. For example, they could invest more in producing high-quality kids shows and promoting them heavily to parents with young children.\n",
        "\n",
        "However, there could also be some negative growth associated with this trend. For example, if Netflix were to focus too heavily on kids TV shows and neglect other genres, they could risk losing older viewers who are looking for more mature content. Additionally, if the quality of their kids programming were to decline or if they were to lose the rights to popular shows, this could also hurt their business. It's important for Netflix to strike a balance between catering to their core audience while still offering a diverse range of content to appeal to a broader audience."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6\n",
        "Duration"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Extract the duration values as integers using regex and plot a histogram\n",
        "sns.histplot(movies['duration'].str.extract('(\\d+)').astype(int), kde=False, color='red')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Movie Durations', fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel('Duration (minutes)')\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(30, 6))\n",
        "\n",
        "# Create a count plot of TV show durations\n",
        "sns.countplot(x=tv_shows['duration'], data=tv_shows, order=tv_shows['duration'].value_counts().index)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Distribution of TV Show Durations\", fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel(\"Duration (seasons)\")\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "# Rotate the x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jqce05b8540e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the duration values as integers using regex\n",
        "movies['minute'] = movies['duration'].str.extract('(\\d+)').apply(pd.to_numeric)\n",
        "\n",
        "# Calculate the average movie duration by rating\n",
        "duration_year = movies.groupby(['rating'])['minute'].mean()\n",
        "\n",
        "# Create a DataFrame to store the results and sort by average duration\n",
        "duration_df = pd.DataFrame(duration_year).sort_values('minute')\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot of the average movie duration by rating\n",
        "ax = sns.barplot(x=duration_df.index, y=duration_df.minute)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Average Movie Duration by Rating\", fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel(\"Rating\")\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel(\"Average Duration (minutes)\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gBP0tOHK59de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the chart to visualize the relationship between movie duration and rating.This chart also shows chart also shows that TV-Y rated movies tend to have shorter runtimes, which could be useful for parents looking for age-appropriate content for their children. Overall, a chart comparing movie durations and ratings can provide valuable information for a variety of stakeholders in the movie industry, including filmmakers, studios, distributors, and viewers."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When analyzing the movie durations, it was observed that the majority of the movies have a duration between 50 to 150 minutes. On the other hand, the TV shows have a large number of single-season shows, which indicates that most of the TV shows on Netflix are relatively new.\n",
        "\n",
        "Furthermore, the analysis showed that movies with a rating of NC-17 have the longest average duration. This might be because the movies with such a rating can explore more mature themes and include more explicit content, which requires a longer runtime to tell a compelling story."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can potentially help create a positive business impact as it allows movie studios and streaming platforms to better understand their audience and tailor their content accordingly. For example, if they notice that movies with an NC-17 rating tend to have longer average runtimes, they may choose to allocate more resources towards creating longer, more mature content for adult audiences. Similarly, if they notice that TV-Y rated movies tend to have shorter runtimes, they may choose to focus on creating shorter.\n",
        "there could also be insights that lead to negative growth. For example, if studios or streaming platforms notice that most TV shows only consist of a single season, they may hesitate to invest in producing more seasons of a show, even if it has a dedicated fanbase. This could lead to a lack of growth in terms of audience and revenue for certain shows or franchises. Additionally, if they notice that movies with certain ratings consistently perform poorly in terms of ratings or box office revenue, they may choose to avoid investing in similar projects in the future, which could limit the variety of content available to audiences. Ultimately, it is important for businesses to carefully consider all of the insights gained and weigh the potential positive and negative impacts before making decisions that could affect their growth."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7\n",
        "Country"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# create a figure with the desired size\n",
        "plt.figure(figsize=(18,5))\n",
        "\n",
        "# create a countplot with the 'country' column\n",
        "# order the bars in descending order by value counts\n",
        "# limit the plot to only show the top 15 countries\n",
        "# hue the plot by content type ('TV Show' or 'Movie')\n",
        "sns.countplot(x=df['country'], order=df['country'].value_counts().index[0:15], hue=df['type'])\n",
        "\n",
        "# rotate the x-axis tick labels by 50 degrees for better visibility\n",
        "plt.xticks(rotation=50)\n",
        "\n",
        "# set the plot title and font size\n",
        "plt.title('Top 15 countries with most contents', fontsize=15, fontweight='bold')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top_two countries where netflix is most popular\n",
        "country=df['country'].value_counts().reset_index()\n",
        "country\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vfw48zie7CZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 countries by count of titles\n",
        "country_order = df['country'].value_counts()[:10].index\n",
        "\n",
        "# Create a dataframe with count of movie and TV show for each country\n",
        "content_data = df[['type', 'country']].groupby('country')['type'].value_counts().unstack().loc[country_order]\n",
        "\n",
        "# Add a column for total count of titles\n",
        "content_data['total'] = content_data.sum(axis=1)\n",
        "\n",
        "# Calculate the ratio of movie and TV show for each country\n",
        "content_data_ratio = (content_data.T / content_data['total']).T[['Movie', 'TV Show']]\n",
        "\n",
        "# Sort the dataframe by movie ratio and plot the horizontal bar chart\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "content_data_ratio.sort_values(by='Movie').plot(kind='barh', stacked=True, ax=ax)\n",
        "\n",
        "# Set the x-axis label and title\n",
        "ax.set_xlabel('Ratio of Titles', fontsize=14)\n",
        "ax.set_title('Ratio of Movie and TV Show by Country', fontsize=18)\n",
        "\n",
        "# Set the legend\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(reversed(handles), reversed(labels), fontsize=12, loc='upper right')\n"
      ],
      "metadata": {
        "id": "n8_reL7j7MJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart can show the number of titles for each country side by side, making it easy to compare them. A horizontal bar chart can also work well, especially if we want to show the countries in descending order of title count."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have analyzed that the United States has the highest number of content on Netflix, followed by India. Interestingly, India has the highest number of movies on Netflix.\n",
        "\n",
        "These insights can be useful for Netflix in a number of ways. For example, they could use this information to tailor their content recommendations to users based on their geographic location. They could also use this information to determine which types of content to focus on producing in the future.\n",
        "\n",
        "However, there are also some potential negative impacts to consider. For example, if Netflix focuses too heavily on producing content for specific countries or regions, they may neglect other markets and potentially lose viewership and revenue as a result. Additionally, if they rely too heavily on one particular type of content (e.g. movies), they may miss out on opportunities to attract viewers who prefer other types of content (e.g. TV shows or documentaries).\n",
        "\n",
        "Overall, while the insights gained from our analysis can certainly be useful for informing business decisions at Netflix, it's important to approach these insights with a balanced and nuanced perspective, taking into account potential positive and negative impacts."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8\n",
        "Originals"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "df['date_added'] = pd.to_datetime(df['date_added'])\n",
        "movies['year_added'] = df['date_added'].dt.year\n",
        "df"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a new column 'originals' which indicates whether a movie is an original or not\n",
        "movies['originals'] = np.where(movies['release_year'] == movies['year_added'], 'Yes', 'No')\n",
        "\n",
        "# Create a pie chart showing the percentage of originals and others in the dataset\n",
        "fig, ax = plt.subplots(figsize=(5,5), facecolor=\"#363336\")\n",
        "ax.patch.set_facecolor('#363336')\n",
        "\n",
        "# Specify the explode parameter to create some separation between the slices\n",
        "explode = (0, 0.1)\n",
        "\n",
        "# Use value_counts() to count the number of movies in each category\n",
        "# and plot a pie chart using the ax.pie() method\n",
        "ax.pie(movies['originals'].value_counts(), explode=explode, autopct='%.2f%%', labels=['Others', 'Originals'],\n",
        "       shadow=True, startangle=90, textprops={'color': \"black\", 'fontsize': 20}, colors=['red', '#F5E9F5'])\n",
        "\n",
        "# Set the title for the plot\n",
        "ax.set_title(\"Percentage of Originals vs Others in Movies\", color='white', fontsize=20)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PaxyEXEf8ZXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pie chart shows us the percentage of originals vs others."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One interesting thing  to note that only 30% of the movies available on the platform were actually released by Netflix themselves. The remaining 70% of movies were added to Netflix after being released by different modes, such as theaters or other streaming platforms.\n",
        "\n",
        "This fact highlights the vast library of movies that Netflix has acquired over the years, providing viewers with a diverse range of content from all around the world. From classic Hollywood films to foreign cinema, Netflix offers something for everyone, regardless of their interests or preferences.\n",
        "\n",
        "So, the next time you're scrolling through Netflix's extensive movie catalog, remember that only a small fraction of what you see is actually original content. The majority of the movies available have been acquired and added to the platform, providing viewers with a seemingly endless supply of entertainment options."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the positive side, the fact that 70% of movies added on Netflix were released earlier by a different mode suggests that Netflix is able to acquire popular content that has already been released elsewhere. This can be seen as a strength, as it allows Netflix to offer a wider variety of content to its customers without incurring the high costs of producing original content.\n",
        "\n",
        "Furthermore, the fact that 30% of movies released on Netflix suggests that Netflix is investing in creating its own original content. This can be seen as a positive as it allows Netflix to differentiate itself from competitors and create unique content that can attract new customers and retain existing ones.\n",
        "\n",
        "However, on the negative side, if Netflix is not able to produce original content that is as popular as the acquired content, it could lead to a decline in subscribers. Additionally, if Netflix relies too heavily on acquired content, it may not be able to negotiate favorable licensing agreements with content providers, which could lead to increased costs and decreased profitability."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9\n",
        "Correlation heatmap"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Preparing data for heatmap\n",
        "df['count'] = 1\n",
        "data = df.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['country']\n",
        "\n",
        "\n",
        "df_heatmap = df.loc[df['country'].isin(data)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'],df['target_ages'],normalize = \"index\").T\n",
        "df_heatmap\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "\n",
        "country_order2 = ['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain',\n",
        "       'Mexico']\n",
        "\n",
        "age_order = ['Adults', 'Teens', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(df_heatmap.loc[age_order,country_order2],cmap=\"YlGnBu\",square=True, linewidth=2.5,cbar=False,\n",
        "            annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":12})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sd6n_yKo-fSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the relationship between variables i choose this chart."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the US and UK are closely aligned with their Netflix target ages, but radically different from, example, India or Japan!\n",
        "\n",
        "Also, Mexico and Spain have similar content on Netflix for different age groups."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "\n",
        "***Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix.***"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): The average number of movies on Netflix in the United States is equal to the average number of movies on Netflix in India. Alternative hypothesis (H1): The average number of movies on Netflix in the United States is greater than the average number of movies on Netflix in India.."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Filter movies only\n",
        "movies = df[df.type == 'Movie']\n",
        "\n",
        "# Filter by country\n",
        "us_movies = movies[movies.country == 'United States']\n",
        "india_movies = movies[movies.country == 'India']\n",
        "\n",
        "# Perform t-test\n",
        "t, p = ttest_ind(us_movies['release_year'], india_movies['release_year'], equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject null hypothesis. The average number of movies on Netflix in the United States is greater than the average number of movies on Netflix in India.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis. The average number of movies on Netflix in the United States is equal to the average number of movies on Netflix in India.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample t-test to obtain the p-value.I used the ttest_ind function from the scipy.stats module to perform the t-test. This test is appropriate for comparing the means of two independent samples, which is what we're doing here by comparing the number of movies on Netflix in the United States and India.\n",
        "\n",
        "It's worth noting that I assumed that the variances of the two populations are not equal (i.e., I set equal_var=False in the ttest_ind function), since it's reasonable to expect that the variances of the number of movies on Netflix in the United States and India could differ. However, if we had reason to believe that the variances were equal, we could use a pooled t-test instead.."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "two sample t-test is appropriate for comparing the means of two independent samples.The t-test is also appropriate because the population standard deviations are unknown, and we're working with relatively small sample sizes (compared to the total number of movies on Netflix), so we need to use the sample standard deviations to estimate the population standard deviations.\n",
        "\n",
        "Additionally, the t-test assumes that the data are normally distributed (or approximately normally distributed), which is a reasonable assumption for this type of data."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "\n",
        "***According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform.***"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis(H0)-there is no significant difference in the number of movies and TV shows added by Netflix across different months. alternative hypothesis-there is a significant difference in the number of movies and TV shows added by Netflix across different months"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Convert the \"date_added\" column to datetime format\n",
        "df[\"date_added\"] = pd.to_datetime(df[\"date_added\"])\n",
        "\n",
        "# Extract the month from the \"date_added\" column\n",
        "df[\"month_added\"] = df[\"date_added\"].dt.month_name()\n",
        "\n",
        "# Create a contingency table of the number of new movies and TV shows added by month\n",
        "contingency_table = pd.crosstab(df[\"type\"], df[\"month_added\"])\n",
        "\n",
        "# Perform a chi-square test for independence\n",
        "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2_statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have choose here chi-square test for independence.The chi-square test is used to determine if there is a significant association between two categorical variables. In this case, we wanted to test if there was a significant association between the time of year and the number of new movies and TV shows added to Netflix. The test involves comparing the observed frequencies of the contingency table (which shows the distribution of the data) to the expected frequencies under the assumption of independence. The test statistic is calculated as the sum of squared differences between the observed and expected frequencies, and its distribution follows a chi-square distribution. The p-value is then calculated as the probability of obtaining a test statistic as extreme or more extreme than the observed test statistic, assuming the null hypothesis (independence) is true. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables.."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test for independence is used because we were interested in testing for a potential association between two categorical variables: the time of year and the number of new movies and TV shows added to Netflix. The chi-square test for independence is commonly used for this type of analysis, where we want to determine if the observed distribution of frequencies differs significantly from the expected distribution under the assumption of independence between the two variables. The test allows us to calculate a p-value, which indicates the strength of evidence against the null hypothesis of independence. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables. Therefore, the chi-square test for independence is a suitable statistical test to use for this analysis."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "***The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform.***"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: The number of movies and TV shows on Netflix is not significantly different.\n",
        "\n",
        "Alternative hypothesis: The number of movies on Netflix is significantly greater than the number of TV shows."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "# Count the number of movies and TV shows\n",
        "n_movies = df[df['type'] == 'Movie'].count()['type']\n",
        "n_tv_shows = df[df['type'] == 'TV Show'].count()['type']\n",
        "\n",
        "# Set the counts and sample sizes for the z-test\n",
        "counts = [n_movies, n_tv_shows]\n",
        "nobs = [len(df), len(df)]\n",
        "\n",
        "# Perform the z-test assuming equal proportions\n",
        "z_stat, p_val = proportions_ztest(counts, nobs, value=0, alternative='larger')\n",
        "\n",
        "# Print the results\n",
        "print('Number of movies:', n_movies)\n",
        "print('Number of TV shows:', n_tv_shows)\n",
        "print('z-statistic:', z_stat)\n",
        "print('p-value:', p_val)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used a two-sample z-test for proportions to obtain the p-value. The null hypothesis for the test is that the proportion of movies and TV shows on Netflix is equal, while the alternative hypothesis is that the proportion of movies is greater than the proportion of TV shows. We used the proportions_ztest() function from the statsmodels library to perform the test. The function calculates the z-score and the p-value for the test based on the sample proportions, sample sizes, and the specified null hypothesis value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two-sample z-test for proportions is used  to compare the number of movies and TV shows on Netflix because the data consists of two categorical variables (movie or TV show), and we want to test if there is a significant difference between the proportions of these categories in the population. The two-sample z-test for proportions is an appropriate test to use when we have two independent samples, and we want to compare the proportion of successes in each sample. In this case, a success refers to a movie or TV show. The test assumes that the samples are large enough to apply the normal approximation to the binomial distribution. Since we have a large sample size in this case, we can use the z-test for proportions to test the hypothesis of interest."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***data cleaning***"
      ],
      "metadata": {
        "id": "WXOZ6LRhCd8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Data %\n",
        "round(df.isna().sum()/len(df)*100, 2).sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "CE-APNQkCbd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df[['director','cast','country']] = df[['director','cast','country']].fillna(' ')\n",
        "df.dropna(axis=0, inplace=True)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for null values after treating them.\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "guyncaxnCyAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot for outlier detection\n",
        "sns.boxplot(data=df)\n"
      ],
      "metadata": {
        "id": "8xS3jiRQC6r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# plotting graph\n",
        "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
        "\n",
        "# Display boxplot and dist plot.\n",
        "sns.distplot(x=df['release_year'], ax=ax[0])\n",
        "sns.boxplot(data=df, ax=ax[1])\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Except for the release year, almost all of the data are presented in text format.\n",
        "\n",
        "2.The textual format contains the data we need to build a cluster/building model. Therefore, there is no need to handle outliers."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)\n",
        "\n",
        "Textual data preprocessing is the process of preparing text data for analysis or modeling. It includes a series of steps that are applied to raw text data in order to clean, organize and standardize it so that it can be easily analyzed or used as input for natural language processing or machine learning models. The preprocessing steps typically include tokenization, stop-word removal, stemming or lemmatization, lowercasing, removing punctuation, and removing numbers. The goal of textual data preprocessing is to prepare the data for further analysis and modeling by removing irrelevant information and standardizing the format of the text. This can help improve the accuracy and effectiveness of the analysis or modeling."
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Modeling Approch***\n",
        "\n",
        "Imagine you're organizing a cluttered closet - you want to group items that have similar attributes to make them easier to find. Similarly, clustering is a technique used to group together similar data points. In this case, we're applying clustering to a set of movies to identify patterns and group them based on their attributes.\n",
        "\n",
        "Before clustering, we need to prepare the textual data. Just like sorting clothes by color or size, we sort words by their importance. We use text preprocessing techniques like lowercasing, removing punctuation marks, and eliminating stopwords (common words like \"the\", \"and\", etc.) that don't add much meaning. Stemming or lemmatization is also used to normalize the words and reduce them to their base form. Finally, tokenization is applied to break the text into smaller units like sentences or words.\n",
        "\n",
        "Now that we've tidied up the data, we can start clustering. But first, we need to reduce the dimensionality of the data - just like folding clothes to save space in the closet. Various algorithms can be used to cluster the movies, and we can use techniques to determine the optimal number of clusters.\n",
        "\n",
        "Once we've built the optimal number of clusters, we can explore their contents using wordclouds. Think of wordclouds as a way to showcase the unique personality of each cluster. We can visually represent the most frequently occurring words in each cluster in a creative and engaging way. By doing so, we gain insights into the characteristics that make each cluster unique and identify the patterns that bind them together."
      ],
      "metadata": {
        "id": "i0Wa9LN9D1E3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "# creating tags column using all text column which one is used for model building purpose.\n",
        "df['tags'] = df['description'] + df['listed_in'] + df['rating'] + df['cast'] + df['country'] + df['director']\n",
        "\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tags[0]"
      ],
      "metadata": {
        "id": "6lkip28EECRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully added all the necessary data into a single column."
      ],
      "metadata": {
        "id": "CEdVlf6CEHQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations\n",
        "\n",
        "Removing punctuation is a common pre-processing step in natural language processing (NLP) tasks. Punctuation marks like periods, commas, and exclamation points can add noise to the data and can sometimes be treated as separate tokens, which can affect the performance of NLP models."
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space, which in effect deletes the punctuation marks.\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)\n",
        "\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tags'] = df['tags'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "lXKxhKgPEeSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tags\n",
        "df.tags[0]"
      ],
      "metadata": {
        "id": "rRS6lpGqEhdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully remove all the punctuation marks from the corpus."
      ],
      "metadata": {
        "id": "qIeKHG4-Elol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces\n",
        "\n",
        "Stop words are words that are commonly used in a language but do not convey much meaning on their own, such as \"a,\" \"an,\" \"the,\" and \"is.\" These words can add noise to the data and can sometimes affect the performance of NLP models, so they are often removed as a pre-processing step."
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# download the stop words list if it is not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# create a set of English stop words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# displaying stopwords\n",
        "np.array(stop_words)"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the stopwords\n",
        "def stopwords(text):\n",
        "    '''a function for removing the stopword and lowercase the each word'''\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "k9aNu8FQFAOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying stopwords function.\n",
        "df['tags'] = df['tags'].apply(stopwords)"
      ],
      "metadata": {
        "id": "IRZ3voSZFIhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tags\n",
        "df.tags[0]"
      ],
      "metadata": {
        "id": "UtKsPgHwFLLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully removed all the stopwords"
      ],
      "metadata": {
        "id": "LNdfyb5RFPgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "#Stemming\n",
        "\n",
        "#Importing snowballstemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# create an object of stemming function\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def stemming(text):\n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appying stemming function\n",
        "\n",
        "df['tags'] = df['tags'].apply(stemming)\n"
      ],
      "metadata": {
        "id": "vAWi_t1MtzxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tags\n",
        "df.tags[0]"
      ],
      "metadata": {
        "id": "NjFSY6Uet6Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have used Stemming. we Used SnowballStemmer to generate a meaningful word out of corpus of words.\n",
        "\n",
        "Stemming is the process of reducing a word to its base or root form. This is a common pre-processing step in natural language processing (NLP) tasks, as it allows you to treat different inflected forms of a word as the same word, which can be useful for tasks like information retrieval or text classification.\n",
        "\n",
        "For example, the words \"run,\" \"runs,\" \"ran,\" and \"running\" are all different inflected forms of the same word \"run,\" and a stemmer can reduce them all to the base form \"run.\""
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "# create the object of tfid vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features = 10000)   # max features = 10000 to prevent system from crashing\n",
        "\n",
        "# fit the vectorizer using the text data\n",
        "tfidf.fit(df['tags'])\n",
        "\n",
        "# collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()\n",
        "\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the object of tfid vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features = 10000)   # max features = 10000 to prevent system from crashing\n",
        "\n",
        "# fit the vectorizer using the text data\n",
        "tfidf.fit(df['tags'])\n",
        "\n",
        "# collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()\n",
        "\n"
      ],
      "metadata": {
        "id": "uZ8ToW9kuwLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing Results\n",
        "print(len(dictionary)) #number of independet features created from \"tags\" columns ---> max_features=10000"
      ],
      "metadata": {
        "id": "93dIH4Rvu1K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vector into array form for clustering\n",
        "vector = tfidf.transform(df['tags']).toarray()\n",
        "\n",
        "# summarize encoded vector\n",
        "print(vector)\n",
        "print(f'shape of the vector : {vector.shape}')\n",
        "print(f'datatype : {type(vector)}')\n"
      ],
      "metadata": {
        "id": "2MJE1bWBu67Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word/Text vectorization is the process of representing words as numerical vectors. This is important in NLP tasks because most machine learning models expect numerical input and cannot work with raw text data directly. Word vectorization allows you to input the words into a machine learning model in a way that preserve the meaning and context of the words. Word vectorization can also be used to measure the similarity between words using vector arithmetic."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction finds a lower number of variables or removes the least important variables from the model. That will reduce the model's complexity and also remove some noise in the data. In this way, dimensionality reduction helps to mitigate overfitting"
      ],
      "metadata": {
        "id": "XHUNZBTCv754"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use PCA (Principal component Analysis) to reduce the dimensionality of data.\n",
        "\n",
        "Dimensionality reduction is the process of reducing the number of features or dimensions in a dataset while preserving as much information as possible. It is a common step in machine learning and data analysis, as high-dimensional datasets can be difficult to work with and can sometimes suffer from the curse of dimensionality."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reducing the dimensions to 3000 using pca\n",
        "pca = PCA(n_components=3000, random_state=42)\n",
        "pca.fit(vector)"
      ],
      "metadata": {
        "id": "AXaEw05OIkjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "X = pca.transform(vector)\n",
        "\n",
        "# shape of transformed vectors\n",
        "X.shape\n"
      ],
      "metadata": {
        "id": "CzOyZAB_z61P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "#K-Means Clustering Algorithm\n",
        "#Elbow method\n",
        "#Elbow Method\n",
        "#Elbow method to find the optimal value of k\n",
        "\n",
        "# Initialize a list to store the sum of squared errors for each value of k\n",
        "SSE = []\n",
        "\n",
        "for k in range(1, 16):\n",
        "  # Initialize the k-means model with the current value of k\n",
        "  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "  # Fit the model to the data\n",
        "  kmeans.fit(X)\n",
        "  # Compute the sum of squared errors for the model\n",
        "  SSE.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the values of SSE\n",
        "plt.plot(range(1, 16), SSE)\n",
        "plt.title('The Elbow Method - KMeans clustering')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Sum of squared errors')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mp5w_LuyIg7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sum of squared distance between each point and the centroid in a cluster decreases with the increase in the number of clusters."
      ],
      "metadata": {
        "id": "QLaafp_6wMLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Silhoutte score method\n",
        "'''Silhouette score method to find the optimal value of k'''\n",
        "\n",
        "# Initialize a list to store the silhouette score for each value of k\n",
        "silhouette_avg = []\n",
        "\n",
        "for k in range(2, 16):\n",
        "  # Initialize the k-means model with the current value of k\n",
        "  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "  # Fit the model to the data\n",
        "  kmeans.fit(X)\n",
        "  # Predict the cluster labels for each point in the data\n",
        "  labels = kmeans.labels_\n",
        "  # Compute the silhouette score for the model\n",
        "  score = silhouette_score(X, labels)\n",
        "  silhouette_avg.append(score)\n",
        "\n",
        "# Plot the Silhouette analysis\n",
        "plt.plot(range(2,16), silhouette_avg)\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest Silhouette score is obtained for 5 clusters.\n",
        "\n",
        "Building 5 clusters using the k-means clustering algorithm:"
      ],
      "metadata": {
        "id": "uO9GdETwxNDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the data into 5 clusters\n",
        "kmeans = KMeans(n_clusters=5, init='k-means++', random_state=33)\n",
        "kmeans.fit(X)\n"
      ],
      "metadata": {
        "id": "fJO8XMGixRJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(X, kmeans.labels_)\n",
        "\n",
        "print((kmeans_distortion, kmeans_silhouette_score))\n"
      ],
      "metadata": {
        "id": "LtLLb1brzU0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "bie7g1CIzdzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing Final Result\n",
        "df.sample(5)[['type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', 'description', 'kmeans_cluster']]"
      ],
      "metadata": {
        "id": "2Uehs--ozilR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(8,5))\n",
        "graph = sns.countplot(x='kmeans_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"
      ],
      "metadata": {
        "id": "3mJlHJt5ztrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 5 clusters using the k-means clustering algorithm."
      ],
      "metadata": {
        "id": "hKCZpnzNz0Gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Building wordclouds for different clusters in K-Means Clustering***"
      ],
      "metadata": {
        "id": "hFbfdxL10KYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Building wordclouds for different clusters in K-Means Clustering\n",
        "def kmeans_worldcloud(cluster_number, column_name):\n",
        "\n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['kmeans_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['kmeans_cluster']==cluster_number]\n",
        "\n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "\n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "1LHKgNE_0M_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word Cloud on \"description\" column for different cluster***\n",
        "\n",
        "***Description***"
      ],
      "metadata": {
        "id": "FegJ6xO60ZrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Description\n",
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "ROerVfI90iUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***cast***"
      ],
      "metadata": {
        "id": "DhD1UwOB0wh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cast\n",
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'cast')\n"
      ],
      "metadata": {
        "id": "Nl8rwAd90yrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Director***"
      ],
      "metadata": {
        "id": "vyW2P5Hd05wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Director\n",
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'director')"
      ],
      "metadata": {
        "id": "JkGTRhSy08zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Listed_in***"
      ],
      "metadata": {
        "id": "F0dCMRC11CBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#listed_in\n",
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "mH2bmycq1En8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Country***"
      ],
      "metadata": {
        "id": "npUbN3Os1SiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#country\n",
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'country')\n"
      ],
      "metadata": {
        "id": "gpiRZzl01UMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Title***"
      ],
      "metadata": {
        "id": "5gCbJpeP1YHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#title\n",
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'title')"
      ],
      "metadata": {
        "id": "RbznbTZo1ZpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2    ***Hierarchical clustering***"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying the agglomerative hierarchical clustering algorithm, the resulting clusters are displayed in a dendrogram, which is a tree-like structure. The dendrogram shows the relationships between the clusters at each level of the hierarchy.\n",
        "\n",
        "To determine the optimal number of clusters for our data, we can visually inspect the dendrogram and look for the largest vertical distance that does not intersect any horizontal line. This distance represents the largest distance between any two merged clusters, and thus the point at which the clusters are most dissimilar.\n",
        "\n",
        "We can then draw a horizontal line at this distance and count the number of vertical lines it intersects. This number corresponds to the optimal number of clusters for our data.\n",
        "\n"
      ],
      "metadata": {
        "id": "GUmG7oAW2Y38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Building a dendogram to decide the number of clusters\n",
        "plt.figure(figsize=(10, 7))\n",
        "dend = shc.dendrogram(shc.linkage(X, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 4, color='r', linestyle='--')\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***At a distance of 4 units, 7 clusters can be built using the agglomerative clustering algorithm.***"
      ],
      "metadata": {
        "id": "RJiKp1nj3gmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building 7 clusters using the Agglomerative clustering algorithm:"
      ],
      "metadata": {
        "id": "KiFTpicM3k33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')\n",
        "hierarchical.fit_predict(X)"
      ],
      "metadata": {
        "id": "hk0ypbCy3qYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a hierarchical cluster number attribute\n",
        "df['hierarchical_cluster'] = hierarchical.labels_"
      ],
      "metadata": {
        "id": "wesjPRum5LkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)[['type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', 'description', 'hierarchical_cluster']]"
      ],
      "metadata": {
        "id": "KUSw5s0V4nxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "graph = sns.countplot(x='hierarchical_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))\n",
        "\n"
      ],
      "metadata": {
        "id": "cvhbP8Pq5U3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 7 clusters using the Agglomerative (hierarchical) clustering algorithm."
      ],
      "metadata": {
        "id": "FM0APZd04DzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Building wordclouds for different clusters in hierarchical Clustering***"
      ],
      "metadata": {
        "id": "Po3jNfeH5bTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hierarchical_worldcloud(cluster_number, column_name):\n",
        "\n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['hierarchical_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['hierarchical_cluster']==cluster_number]\n",
        "\n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "\n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kcb2_O4o5fhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word Cloud on \"title\" column for different cluster***"
      ],
      "metadata": {
        "id": "cH2lHuAK5kSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'title')\n"
      ],
      "metadata": {
        "id": "KsAruB4V5o2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Word Cloud on \"description\" column for different cluster***\n",
        "\n",
        "***Description***"
      ],
      "metadata": {
        "id": "BIzgn_Mo5ux5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#description\n",
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "cOlWgmi550Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Cast***"
      ],
      "metadata": {
        "id": "sVax7gWf55AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cast\n",
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'cast')\n"
      ],
      "metadata": {
        "id": "UvEg3aAp56zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Country***"
      ],
      "metadata": {
        "id": "DEqShkyf6WVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'country')\n"
      ],
      "metadata": {
        "id": "WUAC7xEZ6ZAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***listed_in***"
      ],
      "metadata": {
        "id": "hFRPx_xH6c-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "qkY0BIzB6fbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3    ***Content Based Recommendation System***"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content-based recommendation systems recommend items to a user by using the similarity of items. This recommender system recommends products or items based on their description or features. It identifies the similarity between the products based on their descriptions.\n",
        "\n",
        "It short notes which items a particular user likes and also the items that the users with behavior and likings like him/her likes, to recommend items to that user.\n",
        "\n",
        "We can build a simple content based recommender system based on the similarity of the movie/shows. If a person has watched a show on Netflix, the recommender system must be able to recommend a list of similar shows that s/he likes. To get the similarity score of the shows, we can use cosine similarity. The similarity between two vectors (A and B) is calculated by taking the dot product of the two vectors and dividing it by the magnitude value. We can simply say that the cosine similarity score of two vectors increases as the angle between them decreases."
      ],
      "metadata": {
        "id": "XKhsJ-xz6sFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# veryfying index\n",
        "df[['show_id', 'title', 'tags']]"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.The dataframe under consideration has a total of 7770 rows. However, due to the removal of some rows containing null values, the last index shown in the dataframe is 7786.\n",
        "\n",
        "2.To build a content-based recommendation system, we calculate the similarity score based on a specific index_id with respect to the corresponding \"tags\" column.\n",
        "\n",
        "3.Failure to reset the index may result in the calculation of cosine similarity for a different index, leading to incorrect recommendations. Hence, resetting the index is essential to ensure that the recommendations are based on the correct index.\n",
        "\n",
        "4.Resetting the index involves assigning a new sequential index to each row of the dataframe, starting from 0. This ensures that each row has a unique and identifiable index, making it easier to perform computations and obtain accurate results.\n",
        "\n",
        "5.Therefore, resetting the index is a crucial step in building a content-based recommendation system, as it ensures that the recommendations are based on the correct index and leads to more accurate and relevant recommendations."
      ],
      "metadata": {
        "id": "j6wsO_Jb7O0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining new dataframe for building recommandation system\n",
        "recommender_df = df.copy()\n",
        "\n",
        "# reseting index\n",
        "recommender_df.reset_index(inplace=True)\n",
        "\n",
        "# checking whether or not reset index properly\n",
        "recommender_df[['show_id', 'title', 'tags']]\n"
      ],
      "metadata": {
        "id": "T56RPvYy7SyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above dataframe We successfully reset the index. Now dataset is ready to build content based recommandation system"
      ],
      "metadata": {
        "id": "Ffq1k4wx7c4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping show-id and index column\n",
        "recommender_df.drop(columns=['index', 'show_id'], inplace=True)"
      ],
      "metadata": {
        "id": "-sCDHORY7fJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting index\n",
        "print(f\"before reset index id for movie 'Zero' : {df[df['title'] == 'Zero'].index[0]}\")  # index[0] --> to locate index position\n",
        "print(f\"after reset index id for movie 'Zero': {recommender_df[recommender_df['title'] == 'Zero'].index[0]}\")\n"
      ],
      "metadata": {
        "id": "hZ7Jy9n77qJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling out transformed array independent features created from tags(cluster) column after performing PCA for dimenssionality reduction.\n",
        "X"
      ],
      "metadata": {
        "id": "S9fHqbON7u5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate cosine similarity\n",
        "similarity = cosine_similarity(X)\n",
        "similarity"
      ],
      "metadata": {
        "id": "YlHCBUtb7ynC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Function for list down top 10 recommended movie on the basis of cosine similarity score.***"
      ],
      "metadata": {
        "id": "liL8TAMw7-JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(movie):\n",
        "    '''\n",
        "    This function list down top ten movies on the basis of similarity score for that perticular movie.\n",
        "    '''\n",
        "    print(f\"If you liked '{movie}', you may also enjoy: \\n\")\n",
        "\n",
        "    # find out index position\n",
        "    index = recommender_df[recommender_df['title'] == movie].index[0]\n",
        "\n",
        "    # sorting on the basis of simliarity score, In order to find out distaces from recommended one\n",
        "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x:x[1])\n",
        "\n",
        "    # listing top ten recommenaded movie\n",
        "    for i in distances[1:11]:\n",
        "        print(df.iloc[i[0]].title)\n"
      ],
      "metadata": {
        "id": "IV92EsVg8Dov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Naruto')"
      ],
      "metadata": {
        "id": "ORefM80u8Hzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "recommend('Our Planet')"
      ],
      "metadata": {
        "id": "uUdjq37P8LNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Phir Hera Pheri')"
      ],
      "metadata": {
        "id": "pHZxnwof8Qhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, our journey through the world of Netflix shows has been an exhilarating one. We successfully clustered the shows into groups based on their similarities and differences, resulting in the creation of a content-based recommender system. This system takes into account key attributes such as director, cast, country, genre, rating, and description.\n",
        "\n",
        "With over 7,787 records and 11 attributes, our exploration began by addressing missing values in the dataset and performing exploratory data analysis (EDA). We discovered that Netflix boasts a larger collection of movies compared to TV shows, with a significant presence of shows from the United States.\n",
        "\n",
        "To tackle the challenge of dimensionality, we transformed the key attributes into a 10,000-feature TF-IDF vectorization and utilized Principal Component Analysis (PCA) to reduce the components to 3,000, capturing more than 80% of the variance.\n",
        "\n",
        "By employing K-Means and Agglomerative clustering algorithms, we successfully grouped the shows into clusters. K-Means determined that 5 clusters were optimal based on the elbow method and Silhouette score analysis, while Agglomerative clustering suggested 7 clusters, visualized through a dendrogram.\n",
        "\n",
        "The journey didn't end there. We went on to create a content-based recommender system that utilizes the cosine similarity matrix. This system provides personalized recommendations based on the user's viewing history, suggesting 10 top-notch shows to explore further.\n",
        "\n",
        "Join us in experiencing the diverse world of Netflix shows and allow our recommender system to be your guide, leading you to your next binge-worthy obsession."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}